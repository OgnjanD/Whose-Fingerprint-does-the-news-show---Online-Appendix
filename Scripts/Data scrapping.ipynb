{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import urllib\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import requests\n",
    "import lxml.html\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / size)     \n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vostok Vesti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_2018 = ['11','12']\n",
    "months_2019 = ['1','2']\n",
    "days_1 = ['1','2','3','4','5','6','7','8','9']\n",
    "days_2 = range(10,32)\n",
    "days_2 = [\"{:02d}\".format(x) for x in days_2]\n",
    "days = days_1 + days_2\n",
    "categories = ['1','2','7','6','3','17','8','10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vostok_urls_2018 = []\n",
    "for a in categories:\n",
    "    for i in months_2018: \n",
    "        for y in log_progress(days):\n",
    "            try:\n",
    "                url = lxml.html.fromstring(requests.get('https://www.vostok.rs/index.php?catnovosti=' + a + '&day=' + y + '&month=' + i + '&year=2018' + '-1&option=btg_arhiva&count=0&akcija=datum').content)\n",
    "                vostok_urls_2018.append(url)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vostok_urls_2019 = []\n",
    "for a in categories:\n",
    "    for i in months_2019: \n",
    "        for y in log_progress(days):\n",
    "            try: \n",
    "                url = lxml.html.fromstring(requests.get('https://www.vostok.rs/index.php?catnovosti=' + a + '&day=' + y + '&month=' + i + '&year=-1' + '-1&option=btg_arhiva&count=0&akcija=datum').content)\n",
    "                vostok_urls_2019.append(url)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vostok_urls = vostok_urls_2018 + vostok_urls_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only relevant links - those containing idnovost are actual articles. Those containing javascript are not articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_links = [x.xpath('//a/@href') for x in vostok_urls]\n",
    "clean_links = [x for y in relevant_links for x in y if 'idnovost' in x and 'javascript' not in x]\n",
    "clean_links = ['https://www.vostok.rs' + x for x in clean_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_links = list(set(clean_links))\n",
    "len(clean_links)\n",
    "np.save(\"clean_links_vostok.npy\", clean_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3837"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = []\n",
    "for x in clean_links:\n",
    "    string = re.findall('catnovosti=(.*?)&idnovost', x)\n",
    "    categories.append(string) \n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for page in log_progress(clean_links): \n",
    "    new_pages = requests.get(page)\n",
    "    pages.append(new_pages)\n",
    "trees = [page.content for page in pages]\n",
    "soups = [BeautifulSoup(tree, 'lxml') for tree in trees]\n",
    "np.save(\"vostok_soups.npy\", trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        title = soup.find(\"div\", {\"class\" : \"col-sm-12 col-xs-12 news_main_headline\"}).findAll('h1')\n",
    "        titles.append(title)\n",
    "    except AttributeError:\n",
    "        titles.append('problem')\n",
    "texts_and_dates = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        text_date = soup.select('div span')\n",
    "        texts_and_dates.append(text_date)\n",
    "    except AttributeError:\n",
    "        texts_and_dates.append(\"problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(\n",
    "    {'title': titles,\n",
    "     'texts_and_dates' : texts_and_dates,\n",
    "     'categories' : categories,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "texts_and_dates    0\n",
       "categories         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('vostok.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sputnik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = range(32)\n",
    "days = [\"{:02d}\".format(x) for x in days]\n",
    "del days[0]\n",
    "categories = ['svet', 'politika', 'ekonomija', 'kultura', 'naoruzanje']\n",
    "months_2018 = ['11', '12']\n",
    "months_2019 = ['01', '02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_urls_2018 = []\n",
    "for a in categories:\n",
    "    for i in months_2018:\n",
    "        for y in log_progress(days): \n",
    "            try: \n",
    "                urls = lxml.html.fromstring(requests.get('https://rs.sputniknews.com/' + a + '/2018'+ i + y).content)\n",
    "                sputnik_urls_2018.append(urls)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_urls_2019 = []\n",
    "for a in categories:\n",
    "    for i in months_2019:\n",
    "        for y in log_progress(days): \n",
    "            try: \n",
    "                urls = lxml.html.fromstring(requests.get('https://rs.sputniknews.com/' + a + '/2019'+ i + y).content)\n",
    "                sputnik_urls_2019.append(urls)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sputnik_urls = sputnik_urls_2018 + sputnik_urls_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only pick up actual articles. When length shorter than 19, the links are calendar archive links, when links contain export they are not articles. When they contain politika they are articles about politics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_links = [x.xpath('//a/@href') for x in sputnik_urls]\n",
    "clean_links = []\n",
    "crap_links = []\n",
    "for y in relevant_links:\n",
    "    for x in y: \n",
    "        for i in categories:\n",
    "            if i in x and 'https' not in x and 'export' not in x and len(x) > 19:\n",
    "                clean_links.append(x)\n",
    "            else: \n",
    "                crap_links.append(x)\n",
    "clean_links = ['https://rs.sputniknews.com' + x for x in clean_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_links = list(set(clean_links))\n",
    "len(clean_links)\n",
    "np.save(\"clean_links_sputnik.npy\", clean_links)\n",
    "clean_links = np.load('clean_links_sputnik.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for page in log_progress(clean_links): \n",
    "    new_pages = requests.get(page)\n",
    "    pages.append(new_pages)\n",
    "trees = [page.content for page in pages]\n",
    "soups = [BeautifulSoup(tree, 'lxml') for tree in trees]\n",
    "np.save(\"sputnik_soups.npy\", soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        title = soup.find(\"div\", {\"class\" : \"b-article__header-title\"}).findAll('h1')\n",
    "        titles.append(title)\n",
    "    except AttributeError:\n",
    "        titles.append('problem')\n",
    "lead_texts = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        lead_text = soup.find(\"div\", {\"class\" : \"b-article__lead\"}).findAll('p')\n",
    "        lead_texts.append(lead_text)\n",
    "    except AttributeError:\n",
    "        lead_texts.append('problem')\n",
    "texts = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        text = soup.find(\"div\", {\"class\" : \"b-article__text\"}).findAll('p')\n",
    "        texts.append(text)\n",
    "    except AttributeError\n",
    "        texts.append('problem')\n",
    "dates = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        date = soup.find(\"meta\", itemprop = \"dateCreated\", content=True)['content']\n",
    "        dates.append(date)\n",
    "    except AttributeError:\n",
    "        dates.append('problem')\n",
    "categories = []\n",
    "for soup in log_progress(soups):\n",
    "    try:\n",
    "        category = soup.find('a', {'itemprop' : \"articleSection\"})\n",
    "        categories.append(category)\n",
    "    except AttributeError:\n",
    "        category.append('problem')\n",
    "categories = [x for x in categories if str(x) != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(\n",
    "    {'title': titles,\n",
    "     'date' : dates,\n",
    "     'lead_text': lead_texts,\n",
    "     'text': texts,\n",
    "     'category' : categories\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "date         0\n",
       "lead_text    0\n",
       "text         0\n",
       "category     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('sputnik.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('sputnik.csv', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
