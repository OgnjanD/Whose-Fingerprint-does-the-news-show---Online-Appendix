{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Serbstemmer.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[nltk_data] Downloading package punkt to /Users/ognjand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import import_ipynb\n",
    "import SerbStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import imblearn\n",
    "import statsmodels.api as sm\n",
    "import wordcloud\n",
    "import sklearn\n",
    "from Serbstemmer import stem_str\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ranksums\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we combine the coder responses with the original data set and the automated features and prepare the data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd= pd.read_csv(\"coders.csv\", encoding = 'utf-8')\n",
    "stopwords = pd.read_csv(\"stopwords.csv\")\n",
    "\n",
    "def connect_frames(name, tag):\n",
    "    name = pd.read_csv('{}_features.csv'.format(name), sep = ',', encoding = 'utf-8')\n",
    "    frames = train_pd\n",
    "    frames = frames.loc[(frames['Q3'] == 'Machine set') & (frames['Q1'] == '{}'.format(tag))]\n",
    "    frames = frames[['Q2','A', 'B', 'C', 'D', 'E', 'F', 'G']]\n",
    "    frames['Q2'] = frames['Q2'].apply(int)\n",
    "    name['Q2'] = name.index\n",
    "    new = pd.merge(name,frames, how = 'left', on = 'Q2')\n",
    "    return new\n",
    "#create all feature data set from all \n",
    "tags = ['OD', 'TD', 'SD', 'DD']\n",
    "ognjan = connect_frames('ognjan', 'OD')\n",
    "teo = connect_frames('teo', 'TD')\n",
    "spela = connect_frames('spela', 'SD')\n",
    "damjan = connect_frames('damjan', 'DD')\n",
    "train = pd.concat([ognjan,teo, spela, damjan], axis=0, ignore_index=True)\n",
    "train = train[['text', 'country-source', 'Q2', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'article_len', 'ratio_not_stop_w', 'avg_word_len', 'title_len', 'ratio_unique_words', 'ner']]\n",
    "train = train.dropna(subset = ['A'])\n",
    "train['ner'] = train['ner'].str.lower()\n",
    "train.A = train.A.eq('Yes').mul(1)\n",
    "train.B = train.B.eq('Yes').mul(1)\n",
    "train.C = train.C.eq('Yes').mul(1)\n",
    "train.D = train.D.eq('Yes').mul(1)\n",
    "train.E = train.E.eq('Yes').mul(1)\n",
    "train.F = train.F.eq('Yes').mul(1)\n",
    "train.G = train.G.eq('Yes').mul(1)\n",
    "#text pre processing\n",
    "stopwords = stopwords[\"words\"].tolist()\n",
    "text = train['text'].tolist()\n",
    "text = [(s[0:s.find('.')]) for s in text]\n",
    "text = [tokenizer.tokenize(x) for x in text]\n",
    "text = [[x.lower() for x in thing] for thing in text]\n",
    "text = [[x for x in thing if x not in stopwords] for thing in text]\n",
    "text = [\" \".join(x) for x in text]\n",
    "text = [stem_str(x) for x in text] #check this stemmer again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA    641\n",
       "RU     467\n",
       "Name: country-source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['country-source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country-source  G\n",
       "RU              0    87.794433\n",
       "                1    12.205567\n",
       "USA             0    98.283931\n",
       "                1     1.716069\n",
       "Name: G, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('country-source')['G'].value_counts(normalize = 'true').mul(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Analysis of all features\n",
    "\n",
    "For the binary categorical data, namely, the frames we use a borrowed approach to Chi-Square analysis from InsightBot(http://www.insightsbot.com/blog/2AeuRL/chi-square-feature-selection-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame variance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiSquare:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.p = None #P-Value\n",
    "        self.chi2 = None #Chi Test Statistic\n",
    "        self.dof = None\n",
    "        \n",
    "        self.dfObserved = None\n",
    "        self.dfExpected = None\n",
    "        \n",
    "    def _print_chisquare_result(self, colX, alpha):\n",
    "        result = \"\"\n",
    "        if self.p<alpha:\n",
    "            result=\"{0} is IMPORTANT for Prediction\".format(colX)\n",
    "        else:\n",
    "            result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n",
    "\n",
    "        print(result)\n",
    "        \n",
    "    def TestIndependence(self,colX,colY, alpha=0.05):\n",
    "        X = self.df[colX].astype(str)\n",
    "        Y = self.df[colY].astype(str)\n",
    "        \n",
    "        self.dfObserved = pd.crosstab(Y,X) \n",
    "        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n",
    "        self.p = p\n",
    "        self.chi2 = chi2\n",
    "        self.dof = dof \n",
    "        \n",
    "        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, index = self.dfObserved.index)\n",
    "        \n",
    "        self._print_chisquare_result(colX,alpha)\n",
    "\n",
    "df = train\n",
    "\n",
    "#Initialize ChiSquare Class\n",
    "cT = ChiSquare(df)\n",
    "\n",
    "#Feature Selection\n",
    "testColumns = ['D','E','F', 'G']\n",
    "for var in testColumns:\n",
    "    cT.TestIndependence(colX=var,colY=\"country-source\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated feature variance analysis \n",
    "article_len, ratio_not_stop_w, avg_word_len, title_len, ratio_unique_words\n",
    "\n",
    "First, we divide the data according to source. \n",
    "Second, we test assumptions to determine the necessery statistical procedure for variance analysis.\n",
    "\n",
    "As assumptions for normality are not met we use a Wilcoxon rank sum test for variance analysis. Because the datasets are of different lenghts, hence not paired, we use the Wilcoxon rank sum test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = train[(train['country-source'] == 'USA')]\n",
    "usa.reset_index(inplace= True)\n",
    "rus = train[(train['country-source'] == 'RU')]\n",
    "rus.reset_index(inplace= True)\n",
    "for feature in ['article_len', 'ratio_not_stop_w', 'avg_word_len', 'title_len', 'ratio_unique_words']:\n",
    "    stat, p = shapiro(train['{}'.format(feature)])\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Feature', feature, 'sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Feature', feature, 'sample does not look Gaussian (reject H0)')\n",
    "        \n",
    "for feature in ['article_len', 'ratio_not_stop_w', 'avg_word_len', 'title_len', 'ratio_unique_words']:\n",
    "    stat, p = ranksums(usa['{}'.format(feature)], rus['{}'.format(feature)])\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Feature', feature, 'does not vary significantly (fail to reject H0 and DROP)')\n",
    "    else:\n",
    "        print('Feature', feature, 'does vary significantly (reject H0 and KEEP)')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing the classifiers for frame prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers which can be tuned for hyperparamters\n",
    "Classifier help function obtained from http://www.davidsbatista.net/blog/2018/02/23/model_optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=5, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "models1 = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 1000] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 600] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 16], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC' : [{'kernel': ['linear'], 'C': [1, 10, 100]},  {'kernel': ['rbf'], 'C': [1, 10, 100], 'gamma': [0.001, 0.0001]} ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data set for frame classifier development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_frames = []\n",
    "for t in [6,7,8,9]:\n",
    "    frame = train.iloc[:,t]\n",
    "    frame = frame.tolist()\n",
    "    issue_frames.append(frame)\n",
    "issue_labels = np.array(issue_frames)\n",
    "issue_labels = np.ndarray.transpose(issue_labels)\n",
    "\n",
    "xi_train, xi_test, yi_train, yi_test = train_test_split(text, issue_labels, test_size=0.2, random_state=42)\n",
    "vectorizer = TfidfVectorizer(max_features = 1500, min_df = 1, max_df = 150)\n",
    "xi_train = vectorizer.fit_transform(xi_train)\n",
    "xi_test = vectorizer.transform(xi_test)\n",
    "#here we take the SMOTE sample\n",
    "sm = SMOTEENN()\n",
    "#here we select which frame the analysis is run for \n",
    "X_res, y_res = sm.fit_sample(xi_train, yi_train[:,0])\n",
    "#use the helper function defined above to test a number of models and hyperparameters\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_res, y_res, scoring='f1_weighted', n_jobs=2)\n",
    "helper1.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers without hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually input frame of interest\n",
    "X_res, y_res = sm.fit_sample(xi_train, yi_train[:,0])\n",
    "classifiers =  [LogisticRegression(), MultinomialNB(), GaussianNB()]\n",
    "for clas in classifiers:\n",
    "    all_accuracies = cross_val_score(estimator = clas , X=X_res, y=y_res, cv=5, scoring = 'f1_weighted') \n",
    "    print(sum(all_accuracies)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the best model for each frame with a number of parameters options for the Count and Tfidf Vectorizer (min and max features and df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings('ignore')\n",
    "features = [[1000, 1500, 2500,4000, 5000, 8000, 10000, 12000,15000, 20000], [1, 5, 10, 50, 100, 200], [50, 100, 150, 250, 300, 450, 500, 1000]]\n",
    "combinations = list(itertools.product(*features))\n",
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "xi_train, xi_test, yi_train, yi_test = train_test_split(text, issue_labels, test_size=0.2, random_state=42)\n",
    "models = []\n",
    "f1 = []\n",
    "vects = []\n",
    "i = 1\n",
    "for e in combinations:\n",
    "    for vectorize in vectorizers:\n",
    "        if e[2] > e[1]: #if max_df > min_df \n",
    "            try:\n",
    "                vectorizer = vectorize(max_features = e[0], min_df =e[1], max_df = e[2])\n",
    "                xi_train = vectorizer.fit_transform(xi_train)\n",
    "                xi_test = vectorizer.transform(xi_test)\n",
    "                #Here we input the best classifier for that frame based on the cell above\n",
    "                classifier = LogisticRegression()\n",
    "                #here we again create the smote sample and the frame of interest\n",
    "                sm = SMOTEENN()\n",
    "                X_resampled, y_resampled = sm.fit_sample(X, y)\n",
    "                X_res, y_res = sm.fit_sample(xi_train, yi_train[:,3])\n",
    "                classifier.fit(X_res, y_res)\n",
    "                predictions = classifier.predict(xi_test)\n",
    "                #here we also input the frame of interest\n",
    "                actual = yi_test[:,3]\n",
    "                if metrics.f1_score(actual, predictions, average = 'weighted') > 0.6:\n",
    "                    f1.append(metrics.f1_score(actual, predictions, average = 'weighted'))\n",
    "                    vects.append((vectorize, e[0], e[1], e[2]))\n",
    "                ints = f1.index(max(f1))\n",
    "                model = [vects[ints], max(f1)]\n",
    "                del y_res, X_res\n",
    "            except:\n",
    "                pass\n",
    "        i+=1\n",
    "        print(i)\n",
    "        xi_train, xi_test, yi_train, yi_test = train_test_split(text, issue_labels, test_size=0.2, random_state=42)\n",
    "models.append(model)\n",
    "#save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the best model and saving vectorizers and trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the best model and report precision and recall rates, as well as f1 from here\n",
    "#The figures presented here are thus the outcome of the best model and hyperparameter combination for that frame \n",
    "#Then that model is combined with the best vectorizer option \n",
    "xi_train, xi_test, yi_train, yi_test = train_test_split(text, issue_labels, test_size=0.20)\n",
    "vectorizer = TfidfVectorizer(max_features = 15000, min_df=1, max_df=150)\n",
    "xi_train = vectorizer.fit_transform(xi_train)\n",
    "xi_test = vectorizer.transform(xi_test)\n",
    "\n",
    "#a smote sample is once again taken\n",
    "sm = SMOTEENN()\n",
    "#The frame of interest is manually input\n",
    "X_res, y_res = sm.fit_sample(xi_train, yi_train[:,1])\n",
    "smote = RandomForestClassifier(n_estimators=16).fit(X_res, y_res)\n",
    "smote_pred = smote.predict(xi_test)\n",
    "#The frame of interest is manually input\n",
    "actual = yi_test[:,1]\n",
    "print(classification_report(actual, smote_pred))\n",
    "classifier.fit(X_res, y_res)\n",
    "predictions = classifier.predict(xi_test)\n",
    "print(classification_report(predictions, actual))\n",
    "#save the vectorizer and classifier for each frame\n",
    "joblib.dump(vectorizer, 'issue_3_vec.pkl')\n",
    "joblib.dump(classifier, 'issue_3_clas.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict frames in entire data set to conduct the country classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv(\"complete_dataset.csv\")\n",
    "test = pd.read_csv('test_features.csv')\n",
    "stopwords = pd.read_csv('stopwords.csv')\n",
    "stopwords = stopwords[\"words\"].tolist()\n",
    "all_text = test['text'].tolist()\n",
    "all_text = [(s[0:s.find('.')]) for s in all_text]\n",
    "all_text = [tokenizer.tokenize(x) for x in all_text]\n",
    "all_text = [[x.lower() for x in thing] for thing in all_text]\n",
    "all_text = [[x for x in thing if x not in stopwords] for thing in all_text]\n",
    "all_text = [\" \".join(x) for x in all_text]\n",
    "all_text = [stem_str(x) for x in all_text] #check this stemmer again\n",
    "predicting_set = m[~m.isin(train)].dropna()\n",
    "\n",
    "models = [('issue_0_clas.pkl', 'issue_0_vec.pkl'), ('issue_1_clas.pkl', 'issue_1_vec.pkl'), ('issue_2_clas.pkl', 'issue_2_vec.pkl'), ('issue_3_clas.pkl', 'issue_3_vec.pkl')]\n",
    "predictions = []\n",
    "\n",
    "for model, vec in models:\n",
    "    loaded_model = joblib.load('{}'.format(model))\n",
    "    loaded_vec = joblib.load('{}'.format(vec))\n",
    "    count = loaded_vec.transform(all_text)\n",
    "    prediction = loaded_model.predict(count)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "serbian_vic = pd.DataFrame(predictions[0])\n",
    "anti_west = pd.DataFrame(predictions[1])\n",
    "pro_russian = pd.DataFrame(predictions[2])\n",
    "russian_might = pd.DataFrame(predictions[3])\n",
    "test['serbian_vic'] = pd.DataFrame(predictions[0])\n",
    "test['anti_west'] = pd.DataFrame(predictions[1])\n",
    "test['pro_russian'] = pd.DataFrame(predictions[2])\n",
    "test['russian_might'] = pd.DataFrame(predictions[3])\n",
    "train = train.rename(columns={'D': 'serbian_vic', 'E': 'anti_west', 'F': 'pro_russian', 'G': 'russian_might'})\n",
    "del train['C']\n",
    "alldata = train.append(test, ignore_index=True)\n",
    "alldata.to_csv(\"new_complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country source classifcation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('new_complete')\n",
    "#preparing the Named Entity Recognition COLUMN \n",
    "featuress = alldata['ner'].tolist() \n",
    "clean_ner = []\n",
    "import re\n",
    "import math\n",
    "for x in featuress:\n",
    "    try:\n",
    "        x = re.sub(r'[^\\w ]', '', x)\n",
    "        clean_ner.append(x)\n",
    "    except:\n",
    "        clean_ner.append(\"string\")\n",
    "y = np.array(all_data['country-source'].values)\n",
    "\n",
    "loaded_vec = joblib.load('issue_0_vec.pkl')\n",
    "count = loaded_vec.transform(clean_ner)\n",
    "count = count.toarray()\n",
    "\n",
    "\n",
    "# several feature selection analyses are conducted first as outlined in the study\n",
    "all_data_m = alldata\n",
    "all_data_m=all_data_m.rename(columns = {'country-source':'source'})\n",
    "all_data_m.source = all_data_m.source.eq('USA').mul(1)\n",
    "all_data_m['source'].value_counts()\n",
    "y = np.array(all_data_m['source'].values)\n",
    "features = all_data_m.iloc[:,2:15]\n",
    "features_n = ['article_len','ratio_not_stop_w','avg_word_len', 'title_len', 'ratio_unique_words',  'B','D', 'E', 'F']\n",
    "X = np.array(features[features_n].values)\n",
    "xg_test, xg_train, yg_test, yg_train = train_test_split(X, y, test_size = 0.2, random_state =42)\n",
    "\n",
    "#univariate feature selection\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, y)\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "#random trees feature selection\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)\n",
    "#Recursive Feature Selection\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 4)\n",
    "fit = rfe.fit(X, y)\n",
    "fit.n_features_\n",
    "fit.support_\n",
    "fit.ranking_\n",
    "#Variance threshold feature selection\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "m = sel.fit_transform(X)\n",
    "\n",
    "\n",
    "#outputs generated from these analyses are manually input in the feature list two cells below - 'features_n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=5, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "models1 = {\n",
    "    'SGD': SGD(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'KNeigboursClassifier': KNeighboursClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC(),\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'SGD' : {'alpha':[0.01, 0.001, 0.0001]},\n",
    "    'KNeighborsClassifier': { 'n_neighbors': [16, 300, 500, 1000], 'leaf_size' :[30, 50, 100, 200]},\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 300, 500, 1000], 'max_depth': [10, 50, 100, 1000] },\n",
    "    'AdaBoostClassifier': { 'n_estimators': [16, 300, 600], 'learning_rate': [0.6, 1.0] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 300, 500], 'learning_rate': [0.6, 0.8, 1.0]},\n",
    "    'SVC' : [ {'kernel': ['linear'], 'C': [1, 10, 100]}  {'kernel': ['rbf'], 'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]}],\n",
    "\n",
    " \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model and hyperparameter combinations for each feature set combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_m = alldata\n",
    "y = np.array(all_data_m['country-source'].values)\n",
    "#feature combinations manually input\n",
    "features_n = ['article_len','ratio_not_stop_w','avg_word_len', 'title_len', 'ratio_unique_words', 'serbian_vic', 'anti_west', 'pro_russian', 'russian_might']\n",
    "X = np.array(all_data_m[features_n].values)\n",
    "X = np.column_stack((X,count))\n",
    "xg_train, xg_test, yg_train, yg_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "#classifier manually input\n",
    "#NOTE THAT SMOTE+ENN IS NOT APPLIED FOR THE COUNTRY CLASSIFICATION TASK\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_res, y_res, scoring='f1_weighted', n_jobs=2)\n",
    "helper1.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models without hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually input frame of interest\n",
    "X_res, y_res = sm.fit_sample(xg_train, xg_train[:,0])\n",
    "classifiers =  [LogisticRegression(), MultinomialNB(), GaussianNB()]\n",
    "for clas in classifiers:\n",
    "    all_accuracies = cross_val_score(estimator = clas , X=X_res, y=y_res, cv=5, scoring = 'f1_weighted') \n",
    "    print(sum(all_accuracies)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 1 and 2 - frame distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA WRANGLING - VALUES MANUALLY INPUT\n",
    "#for figure 1\n",
    "df = pd.DataFrame({\"Serbian victimhood\": [66, 60],\n",
    "\"Anti-West\": [34, 81],\n",
    " \"Pro-Russian\": [14, 39],\n",
    " \"Russian might\": [11, 57]}).T\n",
    "df = df.reset_index()\n",
    "df.columns = ['frame','USA','RUS']\n",
    "\n",
    "#for figure 2\n",
    "df = pd.DataFrame({\"Serbian victimhood\": [205, 304],\n",
    "\"Anti-West\": [80, 107],\n",
    " \"Pro-Russian\": [188, 426],\n",
    " \"Russian might\": [110, 376]}).T\n",
    "df = df.reset_index()\n",
    "df.columns = ['frame','USA','RUS']\n",
    "\n",
    "dflong = df.melt(id_vars='frame').rename({\"value\":\"yes\", \"variable\": \"country\"},axis=1)\n",
    "dflong\n",
    "import numpy as np\n",
    "#for figure 1\n",
    "dflong['no'] = np.where(dflong['country']=='USA', 641 - dflong['yes'], 467 - dflong['yes'])\n",
    "#for figure 2 \n",
    "dflong['no'] = 5860 - dflong['yes']\n",
    "\n",
    "df_reconstructed1 = dflong.loc[dflong.index.repeat(dflong.yes)]\n",
    "df_reconstructed1['value'] = 1\n",
    "df_reconstructed1.drop(['yes','no'], axis=1, inplace=True)\n",
    "df_reconstructed1\n",
    "df_reconstructed2 = dflong.loc[dflong.index.repeat(dflong.no)]\n",
    "df_reconstructed2['value'] = 0\n",
    "df_reconstructed2.drop(['yes','no'], axis=1, inplace=True)\n",
    "df_reconstructed2\n",
    "df_reconstructed = pd.concat([df_reconstructed1, df_reconstructed2])\n",
    "\n",
    "\n",
    "#Visualising\n",
    "sns.set(palette=\"gray_r\", font_scale = 1.1)\n",
    "plt.figure(figsize=(10,6))\n",
    "myplot = sns.barplot(data=df_reconstructed, y='value', x = 'frame', hue='country', ci=95)absolute_values = df_reconstructed.groupby(['frame', 'country']).agg(sum)['value']\n",
    "\n",
    "y = np.array([0, 0.30])\n",
    "\n",
    "for i, p in enumerate(myplot.patches):\n",
    "\n",
    "    myplot.annotate(format(p.get_height(), '.1%'), \n",
    "                    (p.get_x() + p.get_width() / 2., \n",
    "                     p.get_height()), \n",
    "                    ha = 'center', \n",
    "                    #va = 'center',\n",
    "                    xytext = (-23, 20), textcoords = 'offset points')\n",
    "    \n",
    "    myplot.annotate(format(f\"n={absolute_values[i]}\", ''), \n",
    "                    (p.get_x() + p.get_width() / 2., \n",
    "                     p.get_height()), \n",
    "                    ha = 'center', \n",
    "                    #va = 'center',\n",
    "                    xytext = (-23, 5), textcoords = 'offset points')\n",
    "plt.yticks(np.arange(y.min(), y.max(), 0.05))\n",
    "plt.grid(axis='y', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated feature variation - Figure 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('complete_dataset.csv', sep = ',')\n",
    "all_data = all_data[all_data['article_len'] < 10000]#drop one outlier of 10,000\n",
    "automated = all_data\n",
    "automated['country-source'].value_counts()\n",
    "\n",
    "all_data = pd.read_csv('complete_dataset.csv', sep = ',')\n",
    "from scipy.stats import zscore\n",
    "all_data = pd.read_csv('complete_dataset.csv', sep = ',')\n",
    "all_data = all_data[all_data['article_len'] < 10000]#drop one outlier of 10,000\n",
    "automated = all_data\n",
    "automated = automated[['country-source', 'article_len', 'title_len', 'ratio_not_stop_w', 'ratio_not_stop_w_t','avg_word_len', 'ratio_unique_words']]\n",
    "automated[['article_len', 'title_len','ratio_not_stop_w', 'ratio_not_stop_w_t','avg_word_len', 'ratio_unique_words']] /= automated[['article_len', 'ratio_not_stop_w', 'ratio_not_stop_w_t','avg_word_len', 'title_len', 'ratio_unique_words']].max()\n",
    "automated[['article_len', 'title_len','ratio_not_stop_w', 'ratio_not_stop_w_t','avg_word_len', 'ratio_unique_words']] = automated[['article_len', 'title_len','ratio_not_stop_w', 'ratio_not_stop_w_t','avg_word_len', 'ratio_unique_words']].apply(zscore)\n",
    "\n",
    "usa = automated.loc[automated['country-source'] == 'USA']\n",
    "rus = automated.loc[automated['country-source'] == 'RU']\n",
    "usa = [usa[i].tolist() for i in usa.columns]\n",
    "rus = [rus[i].tolist() for i in rus.columns]\n",
    "usa.pop(0)\n",
    "rus.pop(0)\n",
    "\n",
    "\n",
    "ticks = ['Article length', 'Title length', 'Ratio substantive words - text', 'Ratio substantive words - title', 'Avgerage word length', 'Ratio unique words']\n",
    "\n",
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp['boxes'], color=color)\n",
    "    plt.setp(bp['whiskers'], color=color)\n",
    "    plt.setp(bp['caps'], color=color)\n",
    "    plt.setp(bp['medians'], color=color)\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "bpl = plt.boxplot(usa, positions=np.array(range(len(usa)))*2.0-0.4, sym='', widths=0.6)\n",
    "bpr = plt.boxplot(rus, positions=np.array(range(len(rus)))*2.0+0.4, sym='', widths=0.6)\n",
    "\n",
    "set_box_color(bpl, '#D7191C')\n",
    "set_box_color(bpr, '#2C7BB6')\n",
    "\n",
    "# draw temporary red and blue lines and use them to create a legend\n",
    "plt.plot([],'-.', c='#D7191C', label='USA')\n",
    "plt.plot([], c='#2C7BB6', label='RUS')\n",
    "plt.legend()\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xticks(rotation=70)\n",
    "plt.xlim(-2, len(ticks)*2)\n",
    "for whisker in bpl['whiskers']:\n",
    "    whisker.set_linestyle('-.')\n",
    "plt.savefig('Automated_features.png', bbox_inches=\"tight\", dpi = 150)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word cloud by country source - Figure 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USA\n",
    "usa = train.loc[train['country-source'] == 'USA']\n",
    "rus = train.loc[train['country-source'] == 'RU']\n",
    "text = usa['text'].tolist()\n",
    "text = [(s[0:s.find('.')]) for s in text]\n",
    "text = [tokenizer.tokenize(x) for x in text]\n",
    "text = [[x.lower() for x in thing] for thing in text]\n",
    "text = [[x for x in thing if x not in stopwords and x != 'izvor' and x !='n1'] for thing in text]# we drop source and outlet name\n",
    "text_usa = \" \".join(x for review in text for x in review)\n",
    "wordcloud = WordCloud().generate(text_usa)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "text = rus['text'].tolist()\n",
    "text = [(s[0:s.find('.')]) for s in text]\n",
    "text = [tokenizer.tokenize(x) for x in text]\n",
    "text = [[x.lower() for x in thing] for thing in text]\n",
    "text = [[x for x in thing if x not in stopwords and x != 'izvor' and x !='vostok' and x!='rt'] for thing in text]\n",
    "text_rus = \" \".join(x for review in text for x in review)\n",
    "\n",
    "wordcloud = WordCloud().generate(text_rus)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 5 and 6 were created in Excel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
